{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3bfe8e-91bf-4d26-9f8f-2eb55dc455ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PE time series saved to: C:\\Users\\flass\\OneDrive\\AI Financial Model\\S&P 500 Chatgpt Version\\sp500_pe_timeseries.csv\n",
      "ðŸ“Š Final shape: (3298667, 392)\n",
      "ðŸ§¼ Sample PE values:\n",
      "      pe_ttm\n",
      "0  23.435265\n",
      "1  21.504510\n",
      "2  23.435265\n",
      "3  21.304746\n",
      "4  21.870640\n",
      "5  21.937258\n",
      "6  22.436535\n",
      "7  22.469843\n",
      "8  22.869371\n",
      "9  23.501794\n"
     ]
    }
   ],
   "source": [
    "# === generate_sp500_pe.py ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = r\"C:\\Users\\flass\\OneDrive\\AI Financial Model\\S&P 500 Chatgpt Version\"\n",
    "df_price = pd.read_parquet(os.path.join(BASE_DIR, \"df_labeled.parquet\"))\n",
    "df_fund = pd.read_parquet(os.path.join(BASE_DIR, \"fundamentals.parquet\"))\n",
    "\n",
    "# === Filter Income and Balance Sheet Data ===\n",
    "df_income = df_fund[df_fund[\"report_type\"] == \"Income_Statement\"]\n",
    "df_income = df_income[[\"ticker\", \"date\", \"netIncome\"]].dropna()\n",
    "\n",
    "df_balance = df_fund[df_fund[\"report_type\"] == \"Balance_Sheet\"]\n",
    "df_balance = df_balance[[\"ticker\", \"date\", \"commonStockSharesOutstanding\"]].dropna()\n",
    "\n",
    "# === Merge & Clean ===\n",
    "df_fundamental = pd.merge(df_income, df_balance, on=[\"ticker\", \"date\"], how=\"inner\")\n",
    "df_fundamental[\"date\"] = pd.to_datetime(df_fundamental[\"date\"])\n",
    "df_fundamental[\"netIncome\"] = pd.to_numeric(df_fundamental[\"netIncome\"], errors=\"coerce\")\n",
    "df_fundamental[\"commonStockSharesOutstanding\"] = pd.to_numeric(df_fundamental[\"commonStockSharesOutstanding\"], errors=\"coerce\")\n",
    "\n",
    "df_fundamental = df_fundamental.sort_values([\"ticker\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "# === Calculate TTM EPS ===\n",
    "df_fundamental[\"ttm_net_income\"] = (\n",
    "    df_fundamental.groupby(\"ticker\")[\"netIncome\"]\n",
    "    .rolling(4, min_periods=4).sum().reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_fundamental[\"ttm_shares\"] = (\n",
    "    df_fundamental.groupby(\"ticker\")[\"commonStockSharesOutstanding\"]\n",
    "    .rolling(4, min_periods=4).mean().reset_index(level=0, drop=True)\n",
    ")\n",
    "\n",
    "df_fundamental[\"ttm_eps\"] = df_fundamental[\"ttm_net_income\"] / (df_fundamental[\"ttm_shares\"] + 1e-6)\n",
    "df_fundamental = df_fundamental.dropna(subset=[\"ttm_eps\"])\n",
    "df_fundamental = df_fundamental[df_fundamental[\"ttm_eps\"] != 0]\n",
    "\n",
    "# === Clean Price Data ===\n",
    "df_price[\"date\"] = pd.to_datetime(df_price[\"date\"])\n",
    "df_price = df_price.dropna(subset=[\"date\", \"ticker\", \"adjusted_close\"])\n",
    "df_price = df_price.sort_values([\"ticker\", \"date\"])\n",
    "df_fundamental = df_fundamental.sort_values([\"ticker\", \"date\"])\n",
    "\n",
    "# === Merge-asof TTM EPS to Daily Price ===\n",
    "pe_dfs = []\n",
    "\n",
    "for ticker in df_price[\"ticker\"].unique():\n",
    "    df_ticker_price = df_price[df_price[\"ticker\"] == ticker]\n",
    "    df_ticker_fund = df_fundamental[df_fundamental[\"ticker\"] == ticker]\n",
    "\n",
    "    if df_ticker_fund.empty:\n",
    "        continue\n",
    "\n",
    "    merged = pd.merge_asof(\n",
    "        df_ticker_price,\n",
    "        df_ticker_fund[[\"date\", \"ttm_eps\"]],\n",
    "        on=\"date\",\n",
    "        direction=\"backward\"\n",
    "    )\n",
    "\n",
    "    merged[\"ticker\"] = ticker\n",
    "    merged[\"pe_ttm\"] = merged[\"adjusted_close\"] / (merged[\"ttm_eps\"] + 1e-6)\n",
    "\n",
    "    pe_dfs.append(merged)\n",
    "\n",
    "# === Combine and Clean ===\n",
    "df_pe = pd.concat(pe_dfs, ignore_index=True)\n",
    "df_pe = df_pe.dropna(subset=[\"pe_ttm\"])\n",
    "df_pe[\"pe_ttm\"] = pd.to_numeric(df_pe[\"pe_ttm\"], errors=\"coerce\")\n",
    "df_pe = df_pe.replace([np.inf, -np.inf], np.nan).dropna(subset=[\"pe_ttm\"])\n",
    "df_pe[\"pe_ttm\"] = df_pe[\"pe_ttm\"].clip(lower=-500, upper=500).round(6)\n",
    "\n",
    "# === Save Clean CSV ===\n",
    "output_path = os.path.join(BASE_DIR, \"sp500_pe_timeseries.csv\")\n",
    "df_pe[[\"ticker\", \"date\", \"adjusted_close\", \"ttm_eps\", \"pe_ttm\"]].to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… PE time series saved to: {output_path}\")\n",
    "print(f\"ðŸ“Š Final shape: {df_pe.shape}\")\n",
    "print(f\"ðŸ§¼ Sample PE values:\\n{df_pe[['pe_ttm']].head(10)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3eaf441-83cf-4c63-9387-177734fef0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker        date  adjusted_close   ttm_eps     pe_ttm\n",
      "0      A  1999-11-18         26.4545  1.128832  23.435286\n",
      "1      A  1999-11-19         24.2750  1.128832  21.504529\n",
      "2      A  1999-11-22         26.4545  1.128832  23.435286\n",
      "3      A  1999-11-23         24.0495  1.128832  21.304765\n",
      "4      A  1999-11-24         24.6883  1.128832  21.870660\n",
      "5      A  1999-11-26         24.7635  1.128832  21.937277\n",
      "6      A  1999-11-29         25.3271  1.128832  22.436555\n",
      "7      A  1999-11-30         25.3647  1.128832  22.469863\n",
      "8      A  1999-12-01         25.8157  1.128832  22.869391\n",
      "9      A  1999-12-02         26.5296  1.128832  23.501815\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.read_csv(output_path)\n",
    "print(df_out.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b944e-c327-4dd0-9d5f-cfd1f6286adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
